{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Dense,Conv2D,MaxPool2D,Dropout,Input,Flatten\n",
    "from keras.models import Model,load_model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Datasets\\facial-keypoints-detection\\training\\training.csv\")\n",
    "df_test = pd.read_csv(r\"D:\\Datasets\\facial-keypoints-detection\\test\\test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Image'] = df['Image'].apply(lambda x: np.fromstring(x, sep=' '))   # convert string into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9216,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Image'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(df['Image'].values) / 255.0  \n",
    "X = X.astype(np.float32)\n",
    "# return each images as 96 x 96 x 1\n",
    "X = X.reshape(-1, 96, 96, 1)\n",
    "\n",
    "y = df[df.columns[:-1]].values #(30 columns)\n",
    "# Normalize the target value, scale values between 0 and 1\n",
    "y = (y)/255.0\n",
    "# shuffle train data \n",
    "X, y = shuffle(X, y, random_state=42)  \n",
    "y = y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Convolutional Neural Network\n",
    "\n",
    "input_layer = Input(shape=(96,96,1))\n",
    "\n",
    "conv_1 = Conv2D(filters=32,kernel_size=(5,5),activation='relu',name=\"conv_1\")(input_layer)\n",
    "max_pool_1 = MaxPool2D(pool_size=(2,2),name='max_pool_1')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(filters=64,kernel_size=(3,3),activation='relu',name='conv_2')(max_pool_1)\n",
    "max_pool_2 = MaxPool2D(pool_size=(2,2),name=\"max_pool_2\")(conv_2)\n",
    "dropout_2 = Dropout(0.1)(max_pool_2)\n",
    "\n",
    "conv_3 = Conv2D(filters=128,kernel_size=(3,3),activation='relu',name=\"conv_3\")(dropout_2)\n",
    "max_pool_3 = MaxPool2D(pool_size=(2,2),name=\"max_pool_3\")(conv_3)\n",
    "dropout_3 = Dropout(0.2)(max_pool_3)\n",
    "\n",
    "conv_4 = Conv2D(filters=256,kernel_size=(3,3),activation='relu',name=\"conv_4\")(dropout_3)\n",
    "max_pool_4 = MaxPool2D(pool_size=(2,2),name=\"max_pool_4\")(conv_4)\n",
    "dropout_4 = Dropout(0.3)(max_pool_4)\n",
    "\n",
    "conv_5 = Conv2D(filters=256,kernel_size=(3,3),activation='relu',name=\"conv_5\")(dropout_4)\n",
    "max_pool_5 = MaxPool2D(pool_size=(2,2),name=\"max_pool_5\")(conv_5)\n",
    "dropout_5 = Dropout(0.1)(max_pool_5)\n",
    "\n",
    "\n",
    "flatten = Flatten(name=\"flatten_layer\")(dropout_5)\n",
    "\n",
    "dense_1 = Dense(156,activation='relu', name=\"dense_1\")(flatten)\n",
    "dense_2 = Dense(128,activation='relu', name=\"dense_2\")(dense_1)\n",
    "dense_3 = Dense(64,activation='relu', name=\"dense_3\")(dense_2)\n",
    "\n",
    "dense_4 = Dense(30,name='dense_4')(dense_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_layer,dense_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 96, 96, 1)]       0         \n",
      "                                                                 \n",
      " conv_1 (Conv2D)             (None, 92, 92, 32)        832       \n",
      "                                                                 \n",
      " max_pool_1 (MaxPooling2D)   (None, 46, 46, 32)        0         \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 44, 44, 64)        18496     \n",
      "                                                                 \n",
      " max_pool_2 (MaxPooling2D)   (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " max_pool_3 (MaxPooling2D)   (None, 10, 10, 128)       0         \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 10, 10, 128)       0         \n",
      "                                                                 \n",
      " conv_4 (Conv2D)             (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pool_4 (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv_5 (Conv2D)             (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " max_pool_5 (MaxPooling2D)   (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten_layer (Flatten)     (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 156)               40092     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               20096     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30)                1950      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1048826 (4.00 MB)\n",
      "Trainable params: 1048826 (4.00 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 3s 262ms/step - loss: 0.0259 - accuracy: 0.0123 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.0072 - accuracy: 0.5940 - val_loss: 0.0062 - val_accuracy: 0.6963\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 2s 249ms/step - loss: 0.0020 - accuracy: 0.3055 - val_loss: 0.0029 - val_accuracy: 0.2523\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 2s 247ms/step - loss: 8.0367e-04 - accuracy: 0.2442 - val_loss: 0.0025 - val_accuracy: 0.2523\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 5.3383e-04 - accuracy: 0.3575 - val_loss: 0.0012 - val_accuracy: 0.2523\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 3.4051e-04 - accuracy: 0.5824 - val_loss: 0.0016 - val_accuracy: 0.6963\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 2.8937e-04 - accuracy: 0.6717 - val_loss: 0.0012 - val_accuracy: 0.6963\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 2.7451e-04 - accuracy: 0.7021 - val_loss: 0.0013 - val_accuracy: 0.6963\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.6185e-04 - accuracy: 0.6957 - val_loss: 0.0013 - val_accuracy: 0.6963\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.5584e-04 - accuracy: 0.6776 - val_loss: 0.0014 - val_accuracy: 0.6963\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 2.4943e-04 - accuracy: 0.6928 - val_loss: 0.0011 - val_accuracy: 0.6963\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.4318e-04 - accuracy: 0.6951 - val_loss: 0.0014 - val_accuracy: 0.6963\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 2.3635e-04 - accuracy: 0.7004 - val_loss: 0.0012 - val_accuracy: 0.6963\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 2.3423e-04 - accuracy: 0.6992 - val_loss: 0.0013 - val_accuracy: 0.6963\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.3036e-04 - accuracy: 0.7004 - val_loss: 0.0012 - val_accuracy: 0.6963\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.1859e-04 - accuracy: 0.7039 - val_loss: 0.0012 - val_accuracy: 0.6963\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.2022e-04 - accuracy: 0.7009 - val_loss: 0.0015 - val_accuracy: 0.6963\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.2081e-04 - accuracy: 0.7050 - val_loss: 0.0013 - val_accuracy: 0.6963\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.2105e-04 - accuracy: 0.7021 - val_loss: 0.0010 - val_accuracy: 0.6963\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 2.1894e-04 - accuracy: 0.7062 - val_loss: 0.0014 - val_accuracy: 0.6963\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 2.0952e-04 - accuracy: 0.7039 - val_loss: 0.0011 - val_accuracy: 0.6963\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.0678e-04 - accuracy: 0.7044 - val_loss: 9.4056e-04 - val_accuracy: 0.6963\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.0454e-04 - accuracy: 0.7079 - val_loss: 0.0011 - val_accuracy: 0.6963\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.0233e-04 - accuracy: 0.7033 - val_loss: 9.9815e-04 - val_accuracy: 0.6963\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 2.0033e-04 - accuracy: 0.7062 - val_loss: 9.3352e-04 - val_accuracy: 0.6963\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.0008e-04 - accuracy: 0.7074 - val_loss: 8.3570e-04 - val_accuracy: 0.6963\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.0337e-04 - accuracy: 0.7068 - val_loss: 9.8511e-04 - val_accuracy: 0.6963\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.0056e-04 - accuracy: 0.7044 - val_loss: 0.0011 - val_accuracy: 0.6963\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.9286e-04 - accuracy: 0.7062 - val_loss: 0.0011 - val_accuracy: 0.6963\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.9204e-04 - accuracy: 0.7074 - val_loss: 9.2810e-04 - val_accuracy: 0.6963\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.8794e-04 - accuracy: 0.7068 - val_loss: 8.5501e-04 - val_accuracy: 0.6963\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.9023e-04 - accuracy: 0.7074 - val_loss: 8.8389e-04 - val_accuracy: 0.6963\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.9023e-04 - accuracy: 0.7068 - val_loss: 8.1217e-04 - val_accuracy: 0.6963\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.8413e-04 - accuracy: 0.7079 - val_loss: 7.7711e-04 - val_accuracy: 0.6963\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 1.8431e-04 - accuracy: 0.7074 - val_loss: 6.6152e-04 - val_accuracy: 0.6963\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 2s 247ms/step - loss: 1.8164e-04 - accuracy: 0.7068 - val_loss: 6.6315e-04 - val_accuracy: 0.6963\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 2s 249ms/step - loss: 1.7712e-04 - accuracy: 0.7074 - val_loss: 7.1345e-04 - val_accuracy: 0.6963\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 2s 247ms/step - loss: 1.7523e-04 - accuracy: 0.7074 - val_loss: 5.8630e-04 - val_accuracy: 0.6963\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 1.7405e-04 - accuracy: 0.7074 - val_loss: 5.5672e-04 - val_accuracy: 0.6963\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 1.7829e-04 - accuracy: 0.7074 - val_loss: 8.2075e-04 - val_accuracy: 0.6963\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.8044e-04 - accuracy: 0.7074 - val_loss: 7.6486e-04 - val_accuracy: 0.6963\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.7317e-04 - accuracy: 0.7074 - val_loss: 6.1762e-04 - val_accuracy: 0.6963\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.7042e-04 - accuracy: 0.7074 - val_loss: 6.2029e-04 - val_accuracy: 0.6963\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.7268e-04 - accuracy: 0.7074 - val_loss: 5.4241e-04 - val_accuracy: 0.6963\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.6514e-04 - accuracy: 0.7074 - val_loss: 5.2582e-04 - val_accuracy: 0.6963\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.6937e-04 - accuracy: 0.7074 - val_loss: 5.0508e-04 - val_accuracy: 0.6963\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.6416e-04 - accuracy: 0.7074 - val_loss: 3.5220e-04 - val_accuracy: 0.6963\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.6916e-04 - accuracy: 0.7074 - val_loss: 4.6369e-04 - val_accuracy: 0.6963\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.6467e-04 - accuracy: 0.7074 - val_loss: 3.7535e-04 - val_accuracy: 0.6963\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.6484e-04 - accuracy: 0.7074 - val_loss: 3.9297e-04 - val_accuracy: 0.6963\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.6213e-04 - accuracy: 0.7074 - val_loss: 4.2315e-04 - val_accuracy: 0.6963\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.6100e-04 - accuracy: 0.7074 - val_loss: 3.9714e-04 - val_accuracy: 0.6963\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.5888e-04 - accuracy: 0.7074 - val_loss: 4.0160e-04 - val_accuracy: 0.6963\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 1.5885e-04 - accuracy: 0.7074 - val_loss: 3.4993e-04 - val_accuracy: 0.6963\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.5808e-04 - accuracy: 0.7074 - val_loss: 4.1827e-04 - val_accuracy: 0.6963\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.5597e-04 - accuracy: 0.7074 - val_loss: 3.4327e-04 - val_accuracy: 0.6963\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.5498e-04 - accuracy: 0.7074 - val_loss: 3.1551e-04 - val_accuracy: 0.6963\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.5430e-04 - accuracy: 0.7074 - val_loss: 3.5367e-04 - val_accuracy: 0.6963\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.5418e-04 - accuracy: 0.7074 - val_loss: 3.0156e-04 - val_accuracy: 0.6963\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.5279e-04 - accuracy: 0.7074 - val_loss: 3.1928e-04 - val_accuracy: 0.6963\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.5392e-04 - accuracy: 0.7074 - val_loss: 3.1622e-04 - val_accuracy: 0.6963\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 1.5099e-04 - accuracy: 0.7074 - val_loss: 2.3710e-04 - val_accuracy: 0.6963\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.5595e-04 - accuracy: 0.7074 - val_loss: 2.3903e-04 - val_accuracy: 0.6963\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.5404e-04 - accuracy: 0.7074 - val_loss: 2.5421e-04 - val_accuracy: 0.6963\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.5258e-04 - accuracy: 0.7074 - val_loss: 2.5908e-04 - val_accuracy: 0.6963\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.5073e-04 - accuracy: 0.7074 - val_loss: 2.6120e-04 - val_accuracy: 0.6963\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.4881e-04 - accuracy: 0.7074 - val_loss: 2.4462e-04 - val_accuracy: 0.6963\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 1.4487e-04 - accuracy: 0.7074 - val_loss: 2.4696e-04 - val_accuracy: 0.6963\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.4487e-04 - accuracy: 0.7074 - val_loss: 2.4294e-04 - val_accuracy: 0.6963\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 1.4249e-04 - accuracy: 0.7074 - val_loss: 2.0530e-04 - val_accuracy: 0.6963\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 1.4161e-04 - accuracy: 0.7074 - val_loss: 2.1079e-04 - val_accuracy: 0.6963\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.3771e-04 - accuracy: 0.7074 - val_loss: 2.0328e-04 - val_accuracy: 0.6963\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.3697e-04 - accuracy: 0.7074 - val_loss: 1.8503e-04 - val_accuracy: 0.6963\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.3725e-04 - accuracy: 0.7074 - val_loss: 1.7220e-04 - val_accuracy: 0.6963\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.3496e-04 - accuracy: 0.7074 - val_loss: 1.7152e-04 - val_accuracy: 0.6963\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.3424e-04 - accuracy: 0.7074 - val_loss: 1.9663e-04 - val_accuracy: 0.6963\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.3100e-04 - accuracy: 0.7074 - val_loss: 1.9532e-04 - val_accuracy: 0.6963\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.2920e-04 - accuracy: 0.7068 - val_loss: 1.6393e-04 - val_accuracy: 0.6963\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.2785e-04 - accuracy: 0.7074 - val_loss: 1.8047e-04 - val_accuracy: 0.6963\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.2648e-04 - accuracy: 0.7068 - val_loss: 1.6416e-04 - val_accuracy: 0.6963\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.2743e-04 - accuracy: 0.7062 - val_loss: 1.6745e-04 - val_accuracy: 0.6963\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.2639e-04 - accuracy: 0.7062 - val_loss: 1.3503e-04 - val_accuracy: 0.6963\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.2548e-04 - accuracy: 0.7068 - val_loss: 1.5386e-04 - val_accuracy: 0.6963\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.2094e-04 - accuracy: 0.7079 - val_loss: 1.5293e-04 - val_accuracy: 0.6963\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.1855e-04 - accuracy: 0.7068 - val_loss: 1.4941e-04 - val_accuracy: 0.6963\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 1.1719e-04 - accuracy: 0.7074 - val_loss: 1.7526e-04 - val_accuracy: 0.6963\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.1847e-04 - accuracy: 0.7074 - val_loss: 1.3144e-04 - val_accuracy: 0.6963\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.1411e-04 - accuracy: 0.7091 - val_loss: 1.2605e-04 - val_accuracy: 0.6963\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.1303e-04 - accuracy: 0.7079 - val_loss: 1.4977e-04 - val_accuracy: 0.6963\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 1.1243e-04 - accuracy: 0.7056 - val_loss: 1.3040e-04 - val_accuracy: 0.6963\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.1189e-04 - accuracy: 0.7097 - val_loss: 1.1037e-04 - val_accuracy: 0.6963\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.0999e-04 - accuracy: 0.7074 - val_loss: 1.1253e-04 - val_accuracy: 0.6986\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 2s 247ms/step - loss: 1.0645e-04 - accuracy: 0.7079 - val_loss: 1.2000e-04 - val_accuracy: 0.6986\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.0561e-04 - accuracy: 0.7114 - val_loss: 1.2052e-04 - val_accuracy: 0.6986\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 1.0333e-04 - accuracy: 0.7155 - val_loss: 1.1684e-04 - val_accuracy: 0.6963\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.0141e-04 - accuracy: 0.7091 - val_loss: 1.1402e-04 - val_accuracy: 0.6986\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 1.0039e-04 - accuracy: 0.7085 - val_loss: 1.1283e-04 - val_accuracy: 0.7009\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 9.8462e-05 - accuracy: 0.7097 - val_loss: 1.1578e-04 - val_accuracy: 0.7056\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 9.7120e-05 - accuracy: 0.7179 - val_loss: 1.1135e-04 - val_accuracy: 0.7009\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 9.5243e-05 - accuracy: 0.7173 - val_loss: 1.2388e-04 - val_accuracy: 0.7009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x131031109d0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=200,epochs=100,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "history = model.save(\"facial_detection_model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(r\"D:\\vs code\\python\\DeepLearning\\Projects\\Facial_landmark_detection\\facial_detection_model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r\"C:\\Users\\Omen\\Desktop\\image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "scaled_face = cv2.resize(gray, (96,96), 0, 0, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (96, 96)\n",
      "Data type: uint8\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", scaled_face.shape)\n",
    "print(\"Data type:\", scaled_face.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_5' (type Functional).\n    \n    Input 0 of layer \"conv_1\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (32, 96)\n    \n    Call arguments received by layer 'model_5' (type Functional):\n      • inputs=tf.Tensor(shape=(32, 96), dtype=uint8)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m points \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_face\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file68slbmqi.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Omen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_5' (type Functional).\n    \n    Input 0 of layer \"conv_1\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (32, 96)\n    \n    Call arguments received by layer 'model_5' (type Functional):\n      • inputs=tf.Tensor(shape=(32, 96), dtype=uint8)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "points = model.predict(scaled_face)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
